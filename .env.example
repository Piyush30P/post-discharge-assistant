# Google Gemini API Key
# Get your key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_gemini_api_key_here

# Pinecone Configuration
# Get your key from: https://app.pinecone.io/
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX_NAME=nephrology-knowledge

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=logs/system_logs.txt

# Database Configuration
DATABASE_PATH=data/patients.db

# PDF Configuration
NEPHROLOGY_PDF_PATH=data/nephrology_book.pdf
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Model Configuration
TEMPERATURE=0.3
MAX_TOKENS=2000
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Local LLM Configuration (Ollama) - For query transformation & summaries
# Avoids Gemini API quota limits for simple tasks
# Install Ollama: https://ollama.com/download
# Then run: ollama pull mistral:7b-instruct
USE_LOCAL_FOR_SIMPLE_TASKS=true
LOCAL_LLM_MODEL=mistral:7b-instruct
OLLAMA_BASE_URL=http://localhost:11434

# Cloud LLM Configuration - For complex medical reasoning only
CLOUD_LLM_MODEL=gemini-2.5-flash